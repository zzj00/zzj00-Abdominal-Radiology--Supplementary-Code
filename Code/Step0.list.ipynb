{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45cf0f85",
   "metadata": {},
   "source": [
    "# 拆分数据集\n",
    "\n",
    "针对What的List模式，进行数据集拆分，形成具有交叉验证或者随机划分的功能。通过test_size参数指定划分的比例。\n",
    "\n",
    "```python\n",
    "def split_dataset(X_data: pd.DataFrame, y_data: pd.DataFrame = None, test_size=0.2, n_trails=10,\n",
    "                  cv: bool = False, shuffle: bool = False, random_state=None, save_dir=None):\n",
    "    \"\"\"\n",
    "    数据划分。\n",
    "    Args:\n",
    "        X_data: 训练数据\n",
    "        y_data: 监督数据\n",
    "        test_size: 测试集比例\n",
    "        n_trails: 尝试多少次寻找最佳数据集划分。\n",
    "        cv: 是否是交叉验证，默认是False，当为True时，n_trails为交叉验证的n_fold\n",
    "        shuffle: 是否进行随机打乱\n",
    "        random_state: 随机种子\n",
    "        save_dir: 信息保存的路径。\n",
    "\n",
    "    Returns: 拆分之后的数据列表\n",
    "\n",
    "    \"\"\"\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd0072",
   "metadata": {},
   "source": [
    "# 单中心数据\n",
    "\n",
    "所有的数据，按照比例划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from onekey_algo import OnekeyDS as okds\n",
    "from onekey_algo.custom.components.comp2 import split_dataset4sol\n",
    "from onekey_algo import get_param_in_cwd\n",
    "\n",
    "label_path = r'C:\\Users\\onekey\\Desktop\\demo/label.csv'\n",
    "\n",
    "# label_path指定你单中心的label文件路径\n",
    "data = pd.read_csv(label_path)\n",
    "rt = split_dataset4sol(data, data['label'], cv=False, save_dir='.',  n_trails=10, test_size=0.3, map_ext='.npy')\n",
    "x1, x2 = rt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfab03",
   "metadata": {},
   "source": [
    "# 多中心数据\n",
    "\n",
    "训练集，按比例划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from onekey_algo.custom.components.comp2 import split_dataset4sol\n",
    "from onekey_algo import get_param_in_cwd\n",
    "from onekey_algo.custom.utils import print_join_info\n",
    "\n",
    "data = pd.read_csv(r'split_info/label-RND-0.csv')\n",
    "train_data = data[data['group'] == 'train']\n",
    "test_data = data[data['group'] != 'train']\n",
    "\n",
    "rt = split_dataset4sol(train_data, train_data['label'], cv=False, n_trails=10, test_size=0.3, save_dir='.', shuffle=True)\n",
    "for idx, (train, val) in enumerate(rt):\n",
    "    val['group'] = 'val'\n",
    "    rnd = pd.concat([train, val, test_data], axis=0)\n",
    "    display(rnd['group'].value_counts())\n",
    "    rnd.to_csv(f'split_info/label-RND-{idx}.csv', index=False)\n",
    "    # 2.5D 数据\n",
    "    rnd['ID'] = rnd['ID'].map(lambda x: x.replace('.gz', '.npy'))\n",
    "    rnd[rnd['group'] == 'train'][['ID', 'label']].to_csv(f'split_info/train-RND-{idx}.txt', sep='\\t', index=False, header=False)\n",
    "    rnd[rnd['group'] != 'train'][['ID', 'label']].to_csv(f'split_info/val-RND-{idx}.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0f4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
